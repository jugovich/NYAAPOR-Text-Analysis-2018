{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYAAPOR Text Analytics Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, download the Kaggle zip file (https://www.kaggle.com/snap/amazon-fine-food-reviews).  And unpack it in this repository's root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../amazon-fine-food-reviews/Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a lot of data.  Let's see what's in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just use a sample for now, so things run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = df.sample(10000).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below a few times, let's take a look at our text and see what it looks like.  Always take a look at your raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.sample(10)['Text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know about you, but I noticed some junk in our data - HTML and URLs.  Let's clear that out first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http[a-zA-Z0-9\\&\\?\\=\\?\\/\\:\\.]+\\b', ' ', text)\n",
    "    text = re.sub(r'\\<[^\\<\\>]+\\>', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['Text'] = df['Text'].map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization (Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's tokenize our text and turn it into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.9, \n",
    "    min_df=5, \n",
    "    ngram_range=(1, 1), \n",
    "    stop_words='english', \n",
    "    max_features=2500\n",
    ")\n",
    "tfidf = tfidf_vectorizer.fit_transform(sample['Text'])\n",
    "ngrams = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because words are really big, by default we work with sparse matrices.  We can expand the sparse matrix with `.todense()` and compute sums like a normal dataframe.  Let's check out the top 20 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_df = pd.DataFrame(tfidf.todense(), columns=ngrams) \n",
    "ngram_df.sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an outcome variable.  How about we try to predict 5-star reviews, and then maybe helpfulness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample['good_score'] = sample['Score'].map(lambda x: 1 if x == 5 else 0)\n",
    "sample['was_helpful'] = ((sample['HelpfulnessNumerator'] / sample['HelpfulnessDenominator']).fillna(0.0) > .80).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_to_predict = 'good_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "results = []\n",
    "kfolds = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created an object that'll split the data into fifths, and then iterate over it five times, holding out one-fifth each time for testing.  Let's do that now.  Each \"fold\" contains an index for training rows, and one for testing rows.  For each fold, we'll train a basic linear Support Vector Machine, and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fold in enumerate(kfolds.split(tfidf, sample[column_to_predict])):\n",
    "    \n",
    "    train, test = fold \n",
    "    print(\"Running new fold, {} training cases, {} testing cases\".format(len(train), len(test)))\n",
    "    \n",
    "    clf = svm.LinearSVC(\n",
    "        max_iter=1000,\n",
    "        penalty='l2',\n",
    "        class_weight='balanced',\n",
    "        loss='squared_hinge'\n",
    "    )\n",
    "    # We picked some decent starting parameters, but encourage you to try out different ones\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html \n",
    "    # If you're ambitious - check out the Scikit-Learn documentation and test out different models\n",
    "    # http://scikit-learn.org/stable/supervised_learning.html\n",
    "    \n",
    "    training_text = tfidf[train]\n",
    "    training_outcomes = sample[column_to_predict].loc[train]\n",
    "    clf.fit(training_text, training_outcomes) # Train the classifier on the training data\n",
    "    \n",
    "    test_text = tfidf[test]\n",
    "    test_outcomes = sample[column_to_predict].loc[test]\n",
    "    predictions = clf.predict(test_text) # Get predictions for the test data\n",
    "    \n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(\n",
    "        test_outcomes, # Compare the predictions against the true outcomes\n",
    "        predictions\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        \"fold\": i,\n",
    "        \"outcome\": 0,\n",
    "        \"precision\": precision[0],\n",
    "        \"recall\": recall[0],\n",
    "        \"fscore\": fscore[0],\n",
    "        \"support\": support[0]\n",
    "    })\n",
    "    \n",
    "    results.append({\n",
    "        \"fold\": i,\n",
    "        \"outcome\": 1,\n",
    "        \"precision\": precision[1],\n",
    "        \"recall\": recall[1],\n",
    "        \"fscore\": fscore[1],\n",
    "        \"support\": support[1]\n",
    "    })\n",
    "    \n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.groupby(\"outcome\").mean()[['precision', 'recall']])\n",
    "print(results.groupby(\"outcome\").std()[['precision', 'recall']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that our model is pretty stable and reasonably performant, we can fit and transform the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf, sample[column_to_predict])  \n",
    "print(metrics.classification_report(sample[column_to_predict].loc[test], predictions))\n",
    "print(metrics.confusion_matrix(sample[column_to_predict].loc[test], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can see what the most predictive features are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ngram_coefs = sorted(zip(ngrams, clf.coef_[0]), key=lambda x: x[1], reverse=True)\n",
    "ngram_coefs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What happens if you change the outcome column to \"was_helpful\" and re-run it again?  Can you think of ways to improve this?  Add stopwords?  Bigrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #{}: {}\".format(\n",
    "            topic_idx,\n",
    "            \", \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find some topics.  We'll check out non-negative matrix factorization (NMF) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=10, random_state=42, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "# Try out different numbers of topics (change n_components)\n",
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "print_top_words(nmf, ngrams, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA is an other popular topic modeling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=10, random_state=42).fit(tfidf)\n",
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "# doc_topic_prior (alpha) - lower alpha means documents will be composed of fewer topics (higher means a more uniform distriution across all topics)\n",
    "# topic_word_prior (beta) - lower beta means topis will be composed of fewer words (higher means a more uniform distribution across all words)\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda, ngrams, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the topic models the same way we did our classifier - everything in Scikit-Learn follows the same fit/transform paradigm.  So, let's get the topics for our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topics = pd.DataFrame(lda.transform(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_column_names = [\"topic_{}\".format(c) for c in doc_topics.columns]\n",
    "doc_topics.columns = topic_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use Pandas to join the topics with the original sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_with_topics = pd.concat([sample, doc_topics], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for patterns by running some means and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_with_topics.groupby(\"Score\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topic_column_names:\n",
    "    print \"{}: {}\".format(topic, sample_with_topics[topic].corr(sample_with_topics['Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "training_data = sample_with_topics[topic_column_names[:-1]] # We're leaving a column out to prevent multicollinearity\n",
    "\n",
    "regression = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regression.fit(training_data, sample_with_topics['Score'])\n",
    "coefficients = regression.coef_\n",
    "print zip(topic_column_names[:-1], coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly Scikit-Learn doesn't make it easy to get p-values or a regression report like you'd normally expect of something like R or Stata.  Scikit-Learn is more about prediction than statistical analysis; for the latter, we can use Statsmodels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "regression = sm.OLS(training_data, sample_with_topics['Score'])\n",
    "results = regression.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check out other unsupervised methods like clustering.  I borrowed/modified some of this code from http://brandonrose.org/clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, max_iter=50, tol=.01)\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "kmeans.fit(tfidf)\n",
    "clusters = kmeans.labels_.tolist() # You can merge these back into the data if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_.argsort()[:, ::-1] \n",
    "for i, closest_ngrams in enumerate(centroids):\n",
    "    print \"Cluster #{}: {}\".format(i, np.array(ngrams)[closest_ngrams[:8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative/Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Uses cosine similarity to get word similarities based on document overlap\n",
    "# To get this for document similarities in terms of word overlap, just drop the .transpose()!\n",
    "similarities = cosine_similarity(tfidf.transpose()) \n",
    "distances = 1 - similarities # Converts to distances\n",
    "clusters = linkage(distances, method='ward') # Run hierarchical clustering on the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, min([len(ngrams)/10.0, 300])))\n",
    "ax = dendrogram(clusters, labels=ngrams, orientation=\"left\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}